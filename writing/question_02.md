# Question 2

_Sound in interactive media traditionally plays a complementary role, augmenting, complementing, or clarifying visual and tactile interactions. Discuss: 1) how breaking this synchronicity—resulting in what Schafer calls schizophonia—can pave the way for sound autonomy, 2) how this autonomy can come to define sound-centric interactions and narratives, and 3) what challenges this poses to information transmission within the action-reaction loop.

## INTRO

Interaction Design is one of the more extensive design disciplines, and there a great number of elements involved. We can focus on a given design's relationship/use of space, time, texture, appearance, etc, but one of the core (and yet often overlooked) aspect of all interactions is sound. Even the most vision-forward or seemingly tactile-focused design includes a sonic element. Take the keyboard that I am currently using to type these words. The color, shape, and font usage on the keys have clearly been thought out. The feel as I press each key is kept fluid so as to minimize finger strain. But there has been serious attention paid to the way it sounds as well. The clicking sound as I type is not too loud as to disturb my neighbors in a coffee shop, but is giving me aural feedback to let me know that I have successfully entered the correct character. 

This attention to sound is important in interaction and user-experience design, and much has been written about how to make it the most successful. Traditionally, much of this study has been born out of sound studies in other design disciplines, including music and sonic broadcast media, narrative screen-based media, and interactive games. Looking at these various fields helps designers learn a great deal about how sound can support the goals of a given interaction, while also pointing the way for new opportunities once we subvert and break this support-centered correlation. 

### PARALLEL SOUND

Film was the first of the twentieth century media to recognize the importance of sound, with the credit of "sound designer" being introduced in the 1970s. Sound designers craft the sonic elements of their films to support the visuals on screen. This can be through traditional "foley" techniques to mimic on-screen events (the soft crunch of walking through falling snow, the brittle snap of a breaking bone) or by using digital recording techniques and processes to augment real-world sounds or create entirely manufactured ones. As they work, these designers often think about sounds as being either diegetic (happening in the world represented by the visuals) or nondiegetic (those sounds outside of the world such as voiceovers and soundtrack). 

Both the diegetic and nondiegetic sounds can be manipulated and processed to strengthen the themes that are presented on screen. Sound designer David Sonnenschein explains how sound can "functions as an interpretive element, guiding the listener towards a certain feeling, subjectively beyond the visual elements." While this is most common with nondiegetic music (the darkness and militaristic pomp of "The Imperial March" as Darth Vader is first introduced in *Star Wars*), sound designers can go to great lengths to create sound effects that also help in that interpretative element (the combination of bear, badger, and dog sounds for Chewbacca's voice that help cement the character as powerful, dangerous, and stalwart).

In the world of sound design for games, Karen Collins breaks these categories down further into nondynamic sounds (which hew more traditionally to the diegetic/nondiegetic divide) and dynamic sounds which are triggered by game state, game environment, or player interaction. These dynamic sounds are particularly useful in both communicating important information to the player and as an opportunity to reinforce the game world and emotional content. For instance, in her analysis of the sound design of *Super Mario Galaxy*'s level-select menu, Elizabeth Medina-Gray comments that

"instead of a bare-bones and entirely functional static sound, the variety of musical pitches elicited by this single and otherwise mundane action might elevate the action to a more playful or joyful mode of engagement, and encourage a player to further experiment with the system (both the actions and the sounds)"

This playfulness is strengthend by the sonic qwualities of that interaction. In fact, as designer Brenda Laurel claims, the "\[t]ight linkage between visual, kinesthetic, and auditory modalities is the key to the sense of immersion that is created by many computer games, simulations, and virtual-reality systems."

These lessons in "interpretive elements" and "tight linkage" are then applied to the field of interaction design. 

However, many practitioners and scholars lament the backseat nature of sound in the design of an overall experience. For Film, Rick Altman discusses what he refers to as "the ontological fallacy" as one of his "Four and a Half Film Fallacies" where film critics have argued that "image without sound still constitutes cinema, while sound without an image is no longer cinema." Altman claims that these arguments are purposefully made to negate the influence of sound on film. Similarly, sound designer Rob Bridgett complains of sound-focused (and often even sound-led) game production teams, "falling back on the old scheduling methodologies that prevent sound from being in a true leadership role." Even Dan Saffer's *Designing for Interaction,* that includes sound as one of the key elements states that "sound is underutilized (some would say rightfully so) in interaction design."  


## NONPARALLEL SOUND

What happens then, when sound does not play a secondary role to the interactive and/or visual goals, and instead functions in a separate and equally important context?

In *The New Soundscape*, R. Murray Schafer introduces the idea of "schizophonia," which he deliberately names in relation to schizophrenia to indicate "the same sense of aberration and drama." Revisiting the topic in *The Tuning of the World (The Soundscape)* he floridly explains:

_Sounds have ben torn from their natural sockets and given amplified and independent existence. Vocal sound, for instance, is no longer tied to a hole in the head but it is free to issue from anywhere in the landscape. In the same instant it may issue from millions of holes in millions of public and private places around the world _

Schafer is skeptical of how recording and transmission technology changes our relationship to the sound around us. Jonathan Sterne, in his introduction to the section on recorded media in *The Sound Studies Reader*, likens Schafer's distrust to Plato's *The Phaedrus* where Socrates prefers living speech over dead paintings because "they go on telling you just one thing forever." We often see this mistrust with new technologies (fear of losing the written word with the advent of the ebook or creativity with the rise of AI tools), but interestingly if look back at those who influenced Schafer we see a different picture

In his *Treatise on Musical Objects,* french composer and electrical engineer Pierre Schaeffer introduces the concept of "acousmatics." For Schaeffer, the fundamental divorce of sound from sound-making object that recorded media facilitates creates an entirely new listening experience. Acousmatics builds on Edmund Husserl's concept of phenomenology, claiming that the new "sonorous object" is more than the original by encompassing the acoustic signal, playback method, playback location reverberation, and listener perception. Additionally, the acousmatic no longer relies on the visual for context. In acousmatic listening, "we listen to the sonorous forms, without any aim other than of hearing them better, in order to be able to describe them through an analysis of our perceptions."

Schaeffer's own *musique concrete* is an example of the acousmatics in practice. By divorcing the sound of a train from the experience of standing in a train-yard in _Étude aux chemins de fer_, Schaeffer is able to present the listener with an entirely new sensation. Further, by manipulating these sounds through chopping, looping and electronically processing, *musique concrete* brings to the acoustic space sounds that did not exist before.

Where Schafer senses danger, Schaeffer sees potential and possibility. What can sound designers do then with this new potentiality of sound divorced from its visual counterparts?

Footnote - Jason Stanyek and Benjamin Piekut propose the term "rhizophonia" as a replacement arguing that schizophonia seeks to describe an exception (sound as separate from source) when in reality "all sound are severed from their sources--that's what makes sound sound."


## SOUND AS SOMETHING ELSE

When we begin to think of sound apart from a supporting role, new possibilities open up to us.

### Sound Autonomy

One potentiality that presents itself for sound in interactive media is brand new combinations of sound and visuals. On her discussion of Schafer's schizophonia in *Playing with Sound*, Karen Collins comments that "more remarkable than the separation of sound from source, however, is our ability to reassociate or integrate that schizophonic sound with a new visual source to create new meanings." This mirrors how sound designers for film create and strengthen emotional and narrative content through their recombinational methods, what film sound theorist Michel Chion's refers to as "synchresis." Relying on physical, psychological, and cultural foundations of certain sounds, designers imbue their soundscapes with new meaning. As mentioned above, these techniques can be pushed to extremes where wholly unrelated sound/visual combinations present radical experiences. A baby's scream replaced with a train whistle or tea kettle communicates new information to the viewer about what this particular episode might signify, a phenomena with sound designer Walter Murch refers to as "conceptual resonance."

Further, games in particular allow for an even deeper relationship as they involve physical interaction from those experiencing the audio and visuals. Collins refers to these as multimodal interactions, and claims that 

"the stakes for players' involvement, interpretation, and therefore attention are much higer in games, so they listen more actively and employ different modes of listenign to guidwe their own movements and actions in the game. Although film may act *on* the body, players act *with* games."

MORE

Beyond this multimodal and referential method of synchresis, acousmatic sound design has the ability to imbue sounds with even deeper meaning. Sonification, which seeks to sonically  communicate complex and often large sets of data (temperature, brain wave patterns, etc.) using sound, is of particular interest here. As Axel Berndt states in his paper from the Ambient@40 conference in 2018:

_It is now possible to use any data stream to modulate one or more parameters automatically. This could be, for instance, the distance between player position and level exit, the number of non-player characters in the scene, the complexity of a puzzle, health meter, mouse cursor movement, or sensor data (e.g. light, accelerometer, microphone). Music now functions as a sonification of this input data, a Musical Auditory Display. [...] Such a Musical Auditory Display establishes a much closer relation to player interaction and the game’s diegesis. It can help to create an even more personalized player experience._

### Sound-centric interactions

There is also the possibility for completely sound-focused interactions, where visuals fill a support role or are otherwise completely absent, and both games and non-playful-interactions have explored this idea. 

Some games have toyed with the idea of completely removing visuals, and the genre of audio-only games has risen from this design goal. While there is a long history of audio-focused games (the electronic game *Simon* from 1978 is an early example), games like *Papa Sangre*, *Dark Echo*, and *Blind Drive* create entirely new worlds and experiences for the player, using only sonic elements. These games are reminiscent of radio plays in the early 20th century, where the listener was able to create and visualize entire worlds. For many of these listeners, these worlds are more robust and real than a screen-based version could ever be. Hugill et al explain how players in *Papa Sangre* "have to rely on imagination to supply the visual component, allowing for some amusing creative possibilities within the game, such as the sound of squeaky toys that are heard when you step on 'bones' that might alert the snuffle hog."

With the ascent of voice-controlled home-control systems such as Google Nest and Amazon's Echo BLAH BLAH

Since these sonic interactions (as with games) are not dependent on physical properties of sounding bodies and spatial acoustics, designers are free to create BLAHBLAH. Spaces Speak

"space no longer serves the role of providing seating for the au- dience. Space becomes the aural equivalent of Escher’s bizarre pictures of impossible objects and spatial geometries: artistic illusions"

Footnote: We see this in other popular media, as in Marilyn Robinson's Pulizter Prize-winning novel Gilead, where the narrator says ""

### Challenges

As we build these new

Limits to users audio understanding

"Furthermore, the experiences of the user, who acts as both ‘composer/musician’ and ‘audience’ in interactive music, are central in a way that is substantially different to the passive listener at an acousmatic concert."



